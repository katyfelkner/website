<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Katy Felkner's Homepage</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&family=Roboto+Serif:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
</head>
<body>
    <header>
        <div class="header-content">
          <img src="katy CC headshot.png" alt="photo of Katy, a white woman with brown hair and red lipstick, outdoors in front of a tree. She is wearing a red shirt and silver jacket." class="header-photo">
          <div class="header-text">
            <h1>Katy Felkner</h1>
            <p>PhD Candidate in LLM Fairness</p>
          </div>
        </div>
    </header>

    <main>
      <div class="content-container">
        <div class="main-content">
        <section class="intro">
            <div class="container">
                <h2>About Me</h2>
                <p>Hi, I'm Katy! I'm a PhD candidate at USC Information Sciences Insitute. I'm a member of <a href="https://cutelab.name">CUTELABNAME</a>, advised by <a href="https://www.isi.edu/~jonmay/"> Jon May</a>. My research focuses on developing high-quality, well-grounded benchmark datasets for fairness in LLMs, with particular emphasis on participatory, community-engaged methods.</p>
                <br>

                <p>I'm passionate about LLM fairness üìù‚öñÔ∏è, ethical AI ü§ñ‚ù§Ô∏è, science communication üë©üèª‚Äçüî¨üì¢, and LGBTQ+ rights üè≥Ô∏è‚Äçüåàüè≥Ô∏è‚Äç‚ößÔ∏è. I also love Star Trek üññ and strategy games üéÆ. </p>
                <br>

                  <p>I am actively seeking research <strong>internships</strong> in responsible AI, <strong>collaborators</strong> for new papers, <strong>USC undergrads</strong> to work with me in the 2025-2026 academic year! If you're interested in working with me, please <a href="mailto:felkner@isi.edi">email me</a> or book a meeting on <a href="https://calendly.com/felkner">my Calendly.</a></p>

                <br>
                 <p>Check out my <a href="felknercv.pdf/felknercv.pdf">full CV</a> or my <a href="felknerresume.pdf/felknerresume.pdf">one-page r√©sum√©</a>! </p>
            </div>
        </section>

        <section class="research">
            <div class="container">
                <h2>Research Interests</h2>
                <ul>
                    <li><strong>LLM Fairness Benchmark Development:</strong> I work on developing targeted benchmark datasets to measure social biases in large language models.</li>
                    <li><strong>Community-Engaged Methods for AI Fairness:</strong> I also focus on participatory methods for fairness benchmark development, ensuring that everyone has a voice in how LLMs treat them.</li>
                    <li><strong>LLM Evaluation:</strong> Recently, I've been exploring how to evaluate fairness of closed-source models. I'm also interested in benchmark validation and in LLM evaluation more generally.</li>
                </ul>
            </div>
        </section>

        <section class="publications">
            <div class="container">
                <h2>Publications</h2>
                <p>These are my peer-reviewed conference and workshop publications.</p>
                <ul>
                    <li><strong>Virginia K. Felkner</strong>, Jennifer A. Thompson, Jonathan May. <a href="https://arxiv.org/abs/2405.15760">GPT is Not an Annotator: The Necessity of Human Annotation
    in Fairness Benchmark Construction. </a>Association for Computational Linguistics, Bangkok, Thailand, Aug. 2024.</li>
                    <li><strong>Virginia K. Felkner</strong>, Ho-Chun Herbert Chang, Eugene Jang, Jonathan May. <a href="https://aclanthology.org/2023.acl-long.507/">WinoQueer: A Community-in-the-Loop
                    Benchmark for Anti-LGBTQ+ Bias in Large Language Models.</a> Association for Computational Linguistics, Toronto, Canada, Jul. 2023.</li>
                    <li><strong>Virginia K. Felkner</strong>, Ho-Chun Herbert Chang, Eugene Jang, Jonathan May. <a href="https://aclanthology.org/2023.acl-long.507/">Towards WinoQueer: Developing a Benchmark
                    for Anti-Queer Bias in Large Language Models.</a> QueerInAI Affinity Group Workshop, North American Association for Computational Linguistics, Seattle, WA, Jul. 2022. </li>
                    <li>Nicolaas Weideman, <strong>Virginia K. Felkner</strong>, Wei-Cheng Wu, Jonathan May, Christophe Hauser, Luis Garcia. <a href="https://dl.acm.org/doi/10.1145/3465413.3488575">PERFUME:
                    Programmatic Extraction and Refinement For Usability of Mathematical Expressions.</a> CheckMATE, ACM SIGSAC Conference on Computer and Communications Securite, New York, NY, Nov. 2021. </li>
                    <li><strong>Virginia K. Felkner</strong> and Elisabeth Moore. <a href="https://mlcsworkshop.weebly.com/uploads/1/1/6/9/116940258/ws_mlcs103s2-file1.pdf">Investigating the Efficacy of Unstructured Text Analysis for Node Failure
                    Detection in Syslog.</a> Second Workshop on Machine Learning for Computing Systems, Supercomputing 2020.</li>
                </ul>
            </div>
        </section>
        <section class="talks">
            <div class="container">
                <h2>Talks, Panels, and Posters</h2>
                <ul>
                    <li>Lightning Talk, Participatory Methods for LLM Bias Benchmarks, Responsible Data Workshop. Sep. 2025.</li>
                    <li>Celebrate Track Invited Speaker, Community-Sourced Bias Metrics for LLMs, UCLA QWERHacks. Feb. 2025.</li>
                    <li>Invited Panelist on Language Matters: Addressing Bias in LLMs, IAPP Privacy. Security. Risk. Sep. 2024.</li>
                    <li>Invited Speaker, John Brooks Slaughter Leadership in Engineering DEI Summit. Feb. 2024.</li>
                    <li>Roundtable Discussion: Defining and Disrupting Antisemitism: Perspectives from Artificial Intelligence, Sociology, History, Law, and Ethics. Association for Jewish Studies, Dec. 2023. </li>
                    <li>Invited Panelist on Generative AI and Biases, QueerInAI Workshop at NeurIPS. Dec. 2023.</li>
                    <li>Guest Lecturer on Ethics and Power in NLP, USC CSCI 662 Advanced NLP, September 2023.</li>
                    <li>Poster Presentation, Anti-Queer Bias in LLMs. CRA-WP Grad Cohort for Women, April 2023.</li>
                    <li>Poster Presentation, Anti-Queer Bias in LLMs. Southern California NLP Symposium, November 2022.</li>
                    <li>Invited Speaker, Anti-Queer Bias in LLMs. USC ISI Natural Language Seminar, June 2022. </li>
                </ul>
            </div>
        </section>


        <section class="media">
            <div class="container">
                <h2>Media Coverage of My Work</h2>
                <ul>
                    <li>USC ISI AI/nsiders Podcast <a href="https://www.youtube.com/watch?v=cbyK0NB_JJA"> Episode 6</a> </li>
                    <li>Los Angeles Blade <a href="https://www.losangelesblade.com/2022/08/12/busting-anti-queer-bias-in-text-prediction/"> Busting Anti-Queer Bias in Text Prediction</a> </li>
                    <li>dotLA <a href="https://dot.la/ai-bias-homophobia-usc-2658219234.html"> Homophobia Is Easy To Encode in AI. One Researcher Built a Program To Change That. </a> </li>
                    <li>Cosmos Magazine <a href="https://cosmosmagazine.com/technology/ai/breaking-down-anti-queer-bias-in-ai-language-models/"> Busting homophobic, anti-queer bias in AI language models </a> </li>
                    <li>USC Viterbi News <a href="https://viterbischool.usc.edu/news/2022/08/lost-in-translation-at-the-border/">Lost in Translation at the Border</a></li>
                    <li>USC Viterbi News <a href="https://viterbischool.usc.edu/news/2022/08/busting-anti-queer-bias-in-text-prediction/">Busting Anti-Queer Bias in Text Prediction</a></li>
                    <li>MultiLingual <a href="https://multilingual.com/developing-machine-translation-to-help-indigenous-refugees-navigate-immigration-courts/">Developing machine translation to help Indigenous refugees navigate immigration courts</a></li>
                </ul>
            </div>
        </section>
        </div>
        <!-- <aside class="twitter-feed">
              <a class="twitter-timeline" data-width="250" data-height="1500" data-theme="dark" href="https://twitter.com/katyfelkner?ref_src=twsrc%5Etfw"></a>
              <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

        </aside> -->
        </div>
    </main>

    <footer>
      <p>Get in touch, book a meeting, or check out my CV!</p>
  <div class="social-buttons">
      <a href="https://www.linkedin.com/in/katyfelkner" target="_blank" class="social-button linkedin">
          <i class="fab fa-linkedin"></i>
      </a>
      <a href="https://github.com/katyfelkner" target="_blank" class="social-button github">
          <i class="fab fa-github"></i>
      </a>
      <a href="https://twitter.com/katyfelkner" target="_blank" class="social-button twitter">
          <i class="fab fa-twitter"></i>
      </a>
      <a href="mailto:felkner@isi.edu" class="social-button email">
            <i class="fas fa-envelope"></i>
        </a>
        <a href="https://calendly.com/felkner" target="_blank" class="social-button calendly">
            <i class="fas fa-calendar"></i>
        </a>
        <a href="felknercv.pdf/felknercv.pdf" target="_blank" class="social-button cv">
            <i class="fas fa-file-alt"></i>
        </a>
        
    </footer>

</body>
</html>
